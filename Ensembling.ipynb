{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "def importing():\n",
    "    df = pd.read_csv( \n",
    "'https://archive.ics.uci.edu/ml/machine-learning-'+\n",
    "'databases/balance-scale/balance-scale.data')\n",
    "    print(df.shape)\n",
    "    print(df.columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(624, 5)\n",
      "Index(['B', '1', '1.1', '1.2', '1.3'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>1.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B  1  1.1  1.2  1.3\n",
       "0  R  1    1    1    2\n",
       "1  R  1    1    1    3\n",
       "2  R  1    1    1    4\n",
       "3  R  1    1    1    5\n",
       "4  R  1    1    2    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = importing()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data\n",
    "def splitting(df):\n",
    "        X = df.drop('B',axis=1).values\n",
    "        y = df['B'].values\n",
    "        \n",
    "        #train_test\n",
    "        X_train,X_test,y_train, y_test = train_test_split(X,y,test_size=0.3, random_state = 42, stratify=y)\n",
    "        \n",
    "        return X,y,X_train,X_test,y_train, y_test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training using the gini\n",
    "def train_gini(X_train,y_train):\n",
    "    # Classification object\n",
    "    clf_gini = DecisionTreeClassifier(criterion='gini', max_depth =3 , min_samples_leaf = 5 , random_state = 42)\n",
    "    \n",
    "    # Fitting the data\n",
    "    clf_gini.fit(X_train,y_train)\n",
    "    \n",
    "    return clf_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_entropy(X_train, y_train):\n",
    "    #classifier making\n",
    "    clf_ent = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_leaf=5,random_state=42)\n",
    "    \n",
    "    clf_ent.fit(X_train,y_train)\n",
    "    \n",
    "    return clf_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions\n",
    "def make_pred(classifier, X_test):\n",
    "    y_pred= classifier.predict(X_test)\n",
    "    print(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculationg Accuracy\n",
    "def cal_accuracy(y_test,y_pred):\n",
    "    print('Confusion_matrix: \\n', \n",
    "          confusion_matrix(y_test,y_pred))\n",
    "    print('Accuracy_score : ', \n",
    "          accuracy_score(y_test,y_pred))\n",
    "    print('classification report:\\n ', \n",
    "          classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data = importing()\n",
    "    X,y,X_train,X_test,y_train, y_test = splitting(data)\n",
    "    clf_gini = train_gini(X_train,y_train)\n",
    "    clf_entropy = train_entropy(X_train,y_train)\n",
    "    \n",
    "    print('Gini')\n",
    "    y_pred_gini = make_pred(clf_gini,X_test)\n",
    "    cal_accuracy(y_test, y_pred_gini)\n",
    "    \n",
    "    print('Entropy')\n",
    "    y_pred_ent = make_pred(clf_entropy,X_test)\n",
    "    cal_accuracy(y_test,y_pred_ent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(624, 5)\n",
      "Index(['B', '1', '1.1', '1.2', '1.3'], dtype='object')\n",
      "Gini\n",
      "['R' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'R' 'R' 'R' 'L' 'R' 'R' 'L' 'R'\n",
      " 'L' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L'\n",
      " 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L'\n",
      " 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'L'\n",
      " 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'L'\n",
      " 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'R' 'R' 'R' 'R' 'R' 'R'\n",
      " 'R' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'L' 'L'\n",
      " 'R' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'L' 'L' 'L' 'L' 'R'\n",
      " 'L' 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'R' 'L'\n",
      " 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'R' 'R' 'R' 'R' 'R' 'R'\n",
      " 'R' 'L' 'R' 'L' 'L' 'L' 'R' 'R']\n",
      "Confusion_matrix: \n",
      " [[ 0  5  9]\n",
      " [ 0 58 29]\n",
      " [ 0 16 71]]\n",
      "Accuracy_score :  0.6861702127659575\n",
      "classification report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           B       0.00      0.00      0.00        14\n",
      "           L       0.73      0.67      0.70        87\n",
      "           R       0.65      0.82      0.72        87\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       188\n",
      "   macro avg       0.46      0.49      0.47       188\n",
      "weighted avg       0.64      0.69      0.66       188\n",
      "\n",
      "Entropy\n",
      "['R' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L'\n",
      " 'L' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L'\n",
      " 'L' 'R' 'R' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L'\n",
      " 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'L' 'L'\n",
      " 'L' 'R' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'L'\n",
      " 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R'\n",
      " 'L' 'R' 'R' 'L' 'R' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'L' 'L'\n",
      " 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'L' 'L' 'L' 'L' 'R'\n",
      " 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'R' 'L'\n",
      " 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'R'\n",
      " 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R']\n",
      "Confusion_matrix: \n",
      " [[ 0  6  8]\n",
      " [ 0 64 23]\n",
      " [ 0 25 62]]\n",
      "Accuracy_score :  0.6702127659574468\n",
      "classification report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           B       0.00      0.00      0.00        14\n",
      "           L       0.67      0.74      0.70        87\n",
      "           R       0.67      0.71      0.69        87\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       188\n",
      "   macro avg       0.45      0.48      0.46       188\n",
      "weighted avg       0.62      0.67      0.64       188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using ensembling with KNN, Logistic and Decision Tree\n",
    "\n",
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier(criterion='gini', max_depth=3, min_samples_leaf=5, random_state=42)\n",
    "\n",
    "classifier = [('KNN', knn),\n",
    "            ('Logistic',lr),\n",
    "            ('Decision tree', dt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(624, 5)\n",
      "Index(['B', '1', '1.1', '1.2', '1.3'], dtype='object')\n",
      "for :KNN\n",
      "accuracy_score : 0.8563829787234043\n",
      "Confusion_matrix \n",
      " : [[ 2  5  7]\n",
      " [ 5 80  2]\n",
      " [ 5  3 79]]\n",
      "classification report\n",
      ":               precision    recall  f1-score   support\n",
      "\n",
      "           B       0.17      0.14      0.15        14\n",
      "           L       0.91      0.92      0.91        87\n",
      "           R       0.90      0.91      0.90        87\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       188\n",
      "   macro avg       0.66      0.66      0.66       188\n",
      "weighted avg       0.85      0.86      0.85       188\n",
      "\n",
      "(624, 5)\n",
      "Index(['B', '1', '1.1', '1.2', '1.3'], dtype='object')\n",
      "for :LOGISTIC\n",
      "accuracy_score : 0.8723404255319149\n",
      "Confusion_matrix \n",
      " : [[ 0  4 10]\n",
      " [ 0 79  8]\n",
      " [ 0  2 85]]\n",
      "classification report\n",
      ":               precision    recall  f1-score   support\n",
      "\n",
      "           B       0.00      0.00      0.00        14\n",
      "           L       0.93      0.91      0.92        87\n",
      "           R       0.83      0.98      0.89        87\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       188\n",
      "   macro avg       0.58      0.63      0.60       188\n",
      "weighted avg       0.81      0.87      0.84       188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(624, 5)\n",
      "Index(['B', '1', '1.1', '1.2', '1.3'], dtype='object')\n",
      "for :DECISION TREE\n",
      "accuracy_score : 0.6861702127659575\n",
      "Confusion_matrix \n",
      " : [[ 0  5  9]\n",
      " [ 0 58 29]\n",
      " [ 0 16 71]]\n",
      "classification report\n",
      ":               precision    recall  f1-score   support\n",
      "\n",
      "           B       0.00      0.00      0.00        14\n",
      "           L       0.73      0.67      0.70        87\n",
      "           R       0.65      0.82      0.72        87\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       188\n",
      "   macro avg       0.46      0.49      0.47       188\n",
      "weighted avg       0.64      0.69      0.66       188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for cl, clf in classifier:\n",
    "    data = importing()\n",
    "    X,y,X_train,X_test,y_train, y_test = splitting(data)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('for :' + cl.upper())\n",
    "    print('accuracy_score :', accuracy_score(y_test,y_pred))\n",
    "   # print('recall_score :', recall_score(y_test,y_pred))\n",
    "    print('Confusion_matrix \\n :', confusion_matrix(y_test,y_pred))\n",
    "    print('classification report\\n:',classification_report(y_test,y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(624, 5)\n",
      "Index(['B', '1', '1.1', '1.2', '1.3'], dtype='object')\n",
      "vc ACCURACY SCORE : 0.6861702127659575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data = importing()\n",
    "X,y,X_train,X_test,y_train, y_test = splitting(data)\n",
    "vc = VotingClassifier(classifier)\n",
    "vc.fit(X_train,y_train) \n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('vc ACCURACY SCORE :' , accuracy_score(y_test,y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
